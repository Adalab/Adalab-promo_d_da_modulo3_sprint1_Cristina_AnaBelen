{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tratamiento de datos\n",
    "# -----------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Gráficos\n",
    "# ------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#  Modelado y matriz de confusión\n",
    "# ------------------------------------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score , cohen_kappa_score, roc_curve,roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "#  Gestión de warnings\n",
    "# ------------------------------------------------------------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair Programming Ajuste\n",
    "Es el momento de realizar el ajuste de vuestro modelo, en este caso tendréis que usar el csv que guardastéis ayer después de todo el preprocesamiento. Los objetivos de esta lección son:\n",
    "\n",
    "    - Realizar el ajuste o ajustes de los modelos\n",
    "    - Sacad la matriz de confusión de vuestro modelo e identificad cuáles son los verdaderos positivos, verdaderos negativos, falsos positivos y falsos negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_est_enc = pd.read_pickle('data/card_est_enc.pkl')\n",
    "df_balanceo = pd.read_pickle('data/df_balanceo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los datos en X e y\n",
    "\n",
    "X1 = df_est_enc.drop(\"fraud\", axis = 1)\n",
    "y1 = df_est_enc[\"fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size = 0.2, random_state = 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos la regresión logistica\n",
    "\n",
    "log_reg_esta = LogisticRegression(n_jobs=-1, max_iter = 1000)\n",
    "\n",
    "# ajustamos el modelo\n",
    "log_reg_esta.fit(x_train1,y_train1)\n",
    "\n",
    "# obtenemos las predicciones para el conjunto de entrenamiento\n",
    "y_pred_train_esta = log_reg_esta.predict(x_train1)\n",
    "\n",
    "# obtenemos las predicciones para el conjunto de test\n",
    "y_pred_test_esta = log_reg_esta.predict(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_esta = pd.DataFrame({'Real': y_train1, 'Predicted': y_pred_train_esta, 'Set': ['Train']*len(y_train1)})\n",
    "test_df_esta  = pd.DataFrame({'Real': y_test1,  'Predicted': y_pred_test_esta,  'Set': ['Test']*len(y_test1)})\n",
    "resultados = pd.concat([train_df_esta,test_df_esta], axis = 0)\n",
    "resultados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATRIZ DE CORRELACIÓN PARA DATOS CODIFICADOS Y  ESTANDARIZADOS\n",
    "\n",
    "mat_lr1 = confusion_matrix(y_test1, y_pred_test_esta)\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "sns.heatmap(mat_lr1, square=True, annot=True, fmt=\"d\", cmap = \"viridis\")\n",
    "\n",
    "plt.xlabel('valor predicho')\n",
    "plt.ylabel('valor real')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los datos en X e y\n",
    "\n",
    "X2 = df_balanceo.drop(\"fraud\", axis = 1)\n",
    "y2 = df_balanceo[\"fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanceo.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos la regresión logistica\n",
    "\n",
    "log_reg = LogisticRegression(n_jobs=-1, max_iter = 1000)\n",
    "\n",
    "# ajustamos el modelo\n",
    "log_reg.fit(x_train2,y_train2)\n",
    "\n",
    "# obtenemos las predicciones para el conjunto de entrenamiento\n",
    "y_pred_train = log_reg_esta.predict(x_train2)\n",
    "\n",
    "# obtenemos las predicciones para el conjunto de test\n",
    "y_pred_test = log_reg_esta.predict(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATRIZ DE CORRELACIÓN PARA DATOS CODIFICADOS Y SIN ESTANDARIZAR\n",
    "\n",
    "mat_lr2 = confusion_matrix(y_test2, y_pred_test)\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "sns.heatmap(mat_lr2, square=True, annot=True, fmt=\"d\", cmap = \"viridis\")\n",
    "\n",
    "plt.xlabel('valor predicho')\n",
    "plt.ylabel('valor real')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejercicio de pair programming anterior ajustastéis vuestro primer modelito de regresión logística. Ahora es el momento de saber como de bueno es nuestro modelo. Para esto, los objetivos del pair de hoy son:\n",
    "\n",
    "Calculad las métricas para vuestro modelo\n",
    "\n",
    "Interpretad las métricas obtenidas, ¿es un buen modelo? ¿hay overfitting o underfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a hacernos una función para sacar las métricas igual que hicimos con al regresión lineal.\n",
    "\n",
    "\n",
    "def metricas(clases_reales_test, clases_predichas_test, clases_reales_train, clases_predichas_train, modelo):\n",
    "    \n",
    "    # para el test\n",
    "    accuracy_test = accuracy_score(clases_reales_test, clases_predichas_test)\n",
    "    precision_test = precision_score(clases_reales_test, clases_predichas_test)\n",
    "    recall_test = recall_score(clases_reales_test, clases_predichas_test)\n",
    "    f1_test = f1_score(clases_reales_test, clases_predichas_test)\n",
    "    kappa_test = cohen_kappa_score(clases_reales_test, clases_predichas_test)\n",
    "\n",
    "    # para el train\n",
    "    accuracy_train = accuracy_score(clases_reales_train, clases_predichas_train)\n",
    "    precision_train = precision_score(clases_reales_train, clases_predichas_train)\n",
    "    recall_train = recall_score(clases_reales_train, clases_predichas_train)\n",
    "    f1_train = f1_score(clases_reales_train, clases_predichas_train)\n",
    "    kappa_train = cohen_kappa_score(clases_reales_train, clases_predichas_train)\n",
    "    \n",
    "\n",
    "    \n",
    "    df = pd.DataFrame({\"accuracy\": [accuracy_test, accuracy_train], \n",
    "                       \"precision\": [precision_test, precision_train],\n",
    "                       \"recall\": [recall_test, recall_train], \n",
    "                       \"f1\": [f1_test, f1_train],\n",
    "                       \"kapppa\": [kappa_test, kappa_train],\n",
    "                       \"set\": [\"test\", \"train\"]})\n",
    "    \n",
    "    df[\"modelo\"] = modelo\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este modelo solo tiene estandarización de las variables con RobustScaler\n",
    "results_logistic_esta = metricas(y_test1, y_pred_test_esta, y_train1, y_pred_train_esta, \"Regresión logistica Esta\")\n",
    "results_logistic_esta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este modelo tiene aplicado el SMOTETomek\n",
    "results_logistic = metricas(y_test2, y_pred_test, y_train2, y_pred_train, \"Regresión logistica balanceado\")\n",
    "results_logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_todo = pd.concat([results_logistic, results_logistic_esta], axis = 0)\n",
    "resultados_todo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anáisis de resultados:\n",
    "\n",
    "En el caso del balanceado, viendo el valor de kappa no podemos descartar que esté acertando por azar, así que, descartaríamos el modelo.\n",
    "\n",
    "En el caso del modelo solo estandarizado, el valor del kappa del train llega casi al 0.7. En este caso revisamos el resto de valores. \n",
    "En nuestro modelo nos interesa minimizar los FN, es decir, casos reales de fraude en los que el modelo nos está diciendo que no es fraude, por lo tanto, nos fijamos a continuación en el recall, que no nos parece en principio un buen dato. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
