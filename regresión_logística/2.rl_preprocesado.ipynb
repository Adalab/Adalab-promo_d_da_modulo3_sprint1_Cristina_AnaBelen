{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Logística - Pair programming ###\n",
    "\n",
    "## 2. Preprocesado ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# -----------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Gráficos\n",
    "# ------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Estandarización variables numéricas y Codificación variables categóricas\n",
    "# -----------------------------------------------------------------------------\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Gestión datos desbalanceados\n",
    "# ------------------------------------------------------------------------------\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Para separar los datos en train y test\n",
    "# ------------------------------------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#  Gestión de warnings\n",
    "# ------------------------------------------------------------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando el mismo dataset que usatéis ayer, los objetivos de los ejercicios de hoy son:\n",
    "\n",
    "Estandarizar las variables numéricas de vuestro set de datos\n",
    "\n",
    "Codificar las variables categóricas. Recordad que tendréis que tener en cuenta si vuestras variables tienen orden o no.\n",
    "\n",
    "Chequear si vuestros datos están balanceados. En caso de que no lo estén utilizad algunas de las herramientas aprendidas en la lección para balancearlos.\n",
    "\n",
    "Guardad el dataframe con los cambios que habéis aplicado para utilizarlo en la siguiente lección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/card_limpio.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a proceder a estandarizar los datos, como tenemos outliers lo haremos con el método RobustScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericas = df.select_dtypes(include = np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construir el modelo de escalador\n",
    "robust = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustamos el modelo utilizando nuestro set de datos\n",
    "robust.fit(numericas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformamos los datos\n",
    "X_robust = robust.transform(numericas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericas_robust = pd.DataFrame(X_robust, columns = numericas.columns)\n",
    "numericas_robust.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columna in numericas_robust.columns:\n",
    "    print(f'La media de la columna {columna} es:  {numericas_robust[columna].mean()}')\n",
    "    print(f'La desviación estándar de la columna {columna} es: {numericas_robust[columna].std()}')\n",
    "    print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 3, ncols = 1, figsize = (30, 10))\n",
    "\n",
    "columnas_robust = numericas_robust.columns\n",
    "axes = axes.flat\n",
    "\n",
    "\n",
    "for i, colum in enumerate(columnas_robust): \n",
    "    sns.histplot(\n",
    "        data = numericas_robust,\n",
    "        x = colum,\n",
    "        kde = True,  \n",
    "        line_kws = {\"linewidth\": 2}, \n",
    "        alpha = 0.2, \n",
    "        ax = axes[i])\n",
    "    \n",
    "    \n",
    "    axes[i].set_title(colum, fontsize = 15, fontweight = \"bold\")\n",
    "    axes[i].tick_params(labelsize = 20)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numericas_robust.columns] = numericas_robust\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a hacer el encoding de las variables categóricas. Vamos a ver el orden:\n",
    "\n",
    "    - repeat_retailer\t**SI** tiene orden\n",
    "    - used_chip\t    **SI** tiene orden\n",
    "    - used_pin_number\t**NO** tiene orden\n",
    "    - online_order  **SI** tiene orden"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces las columnas que tienen orden las dejamos como están puesto que son binarias, y la columna que no tiene orden (used_pin_number) le vamos a aplicar get_dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummies = pd.get_dummies(df[\"used_pin_number\"], prefix_sep = \"_\", prefix = \"used_pin_number\", dtype = int)\n",
    "# dummies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_est_enc = pd.concat([df, dummies], axis = 1)\n",
    "# df_est_enc.drop('used_pin_number', axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_est_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('data/card_est_enc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para aplicar este método lo primero que tenemos que hacer es separar en X e y y en train y test como aprendimos en la lecciones de regresion lineal\n",
    "y = df['fraud']\n",
    "X = df.drop('fraud', axis=1)\n",
    "\n",
    "\n",
    "#dividimos en sets de entrenamiento y test\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iniciamos el método\n",
    "os_us = SMOTETomek()\n",
    "\n",
    "# ajustamos el modelo\n",
    "X_train_res, y_train_res = os_us.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comprobemos como han quedado ahora las categorías después del ajuste\n",
    "\n",
    "print (f\"Distribution before resampling \\n {y_train.value_counts()}\" )\n",
    "print(\"..............................................................\")\n",
    "print (f\"Distribución después del ajuste \\n {y_train_res.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanceo = pd.concat([y_train_res, X_train_res], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanceo.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_balanceo.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanceo['fraud'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanceo.to_pickle('data/df_balanceo.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
